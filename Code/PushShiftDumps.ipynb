{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3524cf6-2e53-4d7a-b3fc-3307dd48c188",
   "metadata": {},
   "source": [
    "https://www.reddit.com/r/pushshift/comments/ajmcc0/comment/ef012vk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "477ea8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS_2021-12.zst [==================================================] 7620.71/7620.71 MB\n",
      "RS_2021-12.zst downloaded.\n",
      "Processed files: 1/24\n",
      "RS_2022-01.zst [==================================================] 8422.33/8422.33 MB\n",
      "RS_2022-01.zst downloaded.\n",
      "Processed files: 2/24\n",
      "RS_2022-02.zst [==================================================] 7966.99/7966.99 MB\n",
      "RS_2022-02.zst downloaded.\n",
      "Processed files: 3/24\n",
      "RS_2022-03.zst [==================================================] 9095.17/9095.17 MB\n",
      "RS_2022-03.zst downloaded.\n",
      "Processed files: 4/24\n",
      "RS_2022-04.zst [==================================================] 9151.39/9151.39 MB\n",
      "RS_2022-04.zst downloaded.\n",
      "Processed files: 5/24\n",
      "RS_2022-05.zst [==================================================] 9881.36/9881.36 MB\n",
      "RS_2022-05.zst downloaded.\n",
      "Processed files: 6/24\n",
      "RS_2022-06.zst [==================================================] 9580.87/9580.87 MB\n",
      "RS_2022-06.zst downloaded.\n",
      "Processed files: 7/24\n",
      "RS_2022-07.zst [==================================================] 10104.38/10104.38 MB\n",
      "RS_2022-07.zst downloaded.\n",
      "Processed files: 8/24\n",
      "RS_2022-08.zst [==================================================] 9955.88/9955.88 MB\n",
      "RS_2022-08.zst downloaded.\n",
      "Processed files: 9/24\n",
      "RS_2022-09.zst [==================================================] 9384.33/9384.33 MB\n",
      "RS_2022-09.zst downloaded.\n",
      "Processed files: 10/24\n",
      "RS_2022-10.zst [==================================================] 9691.67/9691.67 MB\n",
      "RS_2022-10.zst downloaded.\n",
      "Processed files: 11/24\n",
      "RS_2022-11.zst [==================================================] 10732.95/10732.95 MB\n",
      "RS_2022-11.zst downloaded.\n",
      "Processed files: 12/24\n",
      "RS_2022-12.zst [==================================================] 11725.11/11725.11 MB\n",
      "RS_2022-12.zst downloaded.\n",
      "Processed files: 13/24\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import requests\n",
    "import ujson\n",
    "import zstandard as zstd\n",
    "\n",
    "# Define the base URL\n",
    "url = \"https://files.pushshift.io/reddit/submissions/\"\n",
    "\n",
    "# Define the range of years and months to download, the start_month is only used for the first year, after that it will start from January.\n",
    "start_year = 2021\n",
    "end_year = 2022\n",
    "start_month = 12\n",
    "end_month = 12\n",
    "\n",
    "current_year = start_year\n",
    "\n",
    "# Create a directory to store the dumpfiles\n",
    "if not os.path.exists(\"dumpfiles\"):\n",
    "    os.makedirs(\"dumpfiles\")\n",
    "    \n",
    "\n",
    "# Create the CSV file\n",
    "\n",
    "with open('../all_raw_csv/trippinthroughtime_data_12_2021.csv', mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['score', \"author\", 'total_awards_received', 'created_utc', 'num_comments', 'selftext', 'title', 'url', \"domain\", \"permalink\", \"id\", \"subreddit_subscribers\",\"num_crossposts\", \"relative_path\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "        # Rest of the code as is\n",
    "\n",
    "    # Set the total number of files to download\n",
    "    total_files = (end_year - start_year + 1) * 12\n",
    "    processed_files = 0\n",
    "    # Iterate through the years and months\n",
    "    for year in range(start_year, end_year+1):\n",
    "        if current_year == year:\n",
    "            month_start = start_month\n",
    "        else:\n",
    "            month_start = 1\n",
    "        for month in range(month_start, end_month+1):\n",
    "            # Create the filename\n",
    "            filename = f\"RS_{year}-{month:02d}.zst\"\n",
    "            file_url = url + filename\n",
    "            # Check if the file already exists in the dumpfiles directory\n",
    "            if os.path.exists(f\"dumpfiles/{filename}\"):\n",
    "                print(f\"{filename} already exists, skipping download.\")\n",
    "            else:\n",
    "            # Build the request\n",
    "                r = requests.get(file_url, stream=True)\n",
    "                # Check if the request is successful\n",
    "                if r.status_code != 200:\n",
    "                    print(f\"{filename} not found.\")\n",
    "                    continue\n",
    "            # Write the file to disk\n",
    "                with open(f\"dumpfiles/{filename}\", 'wb') as f:\n",
    "                    file_size = int(r.headers.get(\"Content-Length\", 0))\n",
    "                    downloaded = 0\n",
    "                    for data in r.iter_content(4096):\n",
    "                        downloaded += len(data)\n",
    "                        f.write(data)\n",
    "                        done = int(50 * downloaded / file_size)\n",
    "                        print(f\"\\r{filename} [{'=' * done}{' ' * (50-done)}] {downloaded/1048576:.2f}/{file_size/1048576:.2f} MB\", end=\"\")\n",
    "                print(f\"\\n{filename} downloaded.\")\n",
    "            with open(f\"dumpfiles/{filename}\", 'rb') as fh:\n",
    "                dctx = zstd.ZstdDecompressor(max_window_size=2147483648)\n",
    "                with dctx.stream_reader(fh) as reader:\n",
    "                    previous_line = \"\"\n",
    "                    while True:\n",
    "                        chunk = reader.read(2**24)  # 16mb chunks\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        try:\n",
    "                            string_data = chunk.decode('utf-8')\n",
    "                        except:\n",
    "                            string_data = chunk.decode('latin-1')\n",
    "                        lines = string_data.split(\"\\n\")\n",
    "\n",
    "                        for i, line in enumerate(lines[:-1]):\n",
    "                            if i == 0:\n",
    "                                line = previous_line + line\n",
    "                            try:\n",
    "                                object = ujson.loads(line)\n",
    "                                if object[\"subreddit\"] == 'trippinthroughtime':\n",
    "                                    writer.writerow({'score': object.get('score',''), 'author': object.get('author',''), 'domain': object.get('domain',''), 'num_crossposts': object.get('num_crossposts',''), 'total_awards_received': object.get('total_awards_received',''), 'created_utc': object.get('created_utc',''), 'num_comments': object.get('num_comments',''), 'selftext': object.get('selftext',''), 'title': object.get('title',''), 'url': object.get('url',''), 'permalink': object.get('permalink',''), 'id': object.get('id',''), 'subreddit_subscribers': object.get('subreddit_subscribers',''),})   \n",
    "                            except KeyError:\n",
    "                                pass\n",
    "                            except ValueError as e:\n",
    "                                \n",
    "                                pass\n",
    "                # delete the file after it was used\n",
    "                os.remove(f\"dumpfiles/{filename}\")\n",
    "                processed_files += 1\n",
    "                print(f\"Processed files: {processed_files}/{total_files}\")\n",
    "\n",
    "                            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1010d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_alex = pd.read_csv('../all_raw_csv/trippinthroughtime_data_all.csv', encoding='latin-1')\n",
    "df_2015 = pd.read_csv('../all_raw_csv/trippinthroughtime_data2015.csv', encoding='latin-1')\n",
    "df_2016 = pd.read_csv('../all_raw_csv/trippinthroughtime_data2016-2018.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec5d0f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40366, 14)\n",
      "(1025, 14)\n",
      "(14061, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df_alex.shape)\n",
    "print(df_2015.shape)\n",
    "print(df_2016.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d276ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_alex, df_2015, df_2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f131a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55452, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c66243df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['score', 'author', 'total_awards_received', 'created_utc',\n",
       "       'num_comments', 'selftext', 'title', 'url', 'domain', 'permalink', 'id',\n",
       "       'subreddit_subscribers', 'num_crossposts', 'relative_path'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb024cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv('../all_raw_csv/trippinthroughtime_data_all_years.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Memes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c69359b6ae85b7b355cd7fe651d90166f8bb81f2b92a82eabc2dd531a72e3ba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
