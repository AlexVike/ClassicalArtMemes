{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Testdatensatz wird erstellt um den OCR-Prozess zu überprüfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../all_csv_images/all_data_all_images_no_duplicates.csv\")\n",
    "test_df = df.sample(n=50)\n",
    "test_df.to_csv('../all_csv_images/test_file.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wurden zwei Methoden ausprobiert um OCR durchzuführen. Als erstes wurde pytessereact in Verbindung mit dem Python Paket PIL ausprobiert. Jedoch waren die Ergebnisse nicht zufriedenstellend, da bei Text der nicht schwarz auf weiß gestanden ist, nicht erkannt wurde. Als zweites wurde die Google Cloud Vision API verwendet. Diese hat eine bessere Erkennungsrate und ist auch für große Mengen an Bildern geeignet. Aus diesem Grund haben wir uns für diese entschieden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der ersten Methode werden die Bilder vor der Verarbeitung von pytesseract mithilfe von PIL vorverarbeitet. Die Bilder werden in Graustufen umgewandelt und daraufhin wird der Kontrast verbessert um mit Pytesseract OCR durchzuführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing OCR: 100%|██████████| 50/50 [00:20<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = (\n",
    "    r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.read_csv('../all_csv_images/test_file.csv')\n",
    "\n",
    "df['ocr_text'] = ''\n",
    "\n",
    "with open(\"ocr_log.txt\", \"w\") as log:\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc='Performing OCR'):\n",
    "        try:\n",
    "            image = Image.open(row['relative_path'])\n",
    "            image = image.convert(\"L\")\n",
    "            contrast = ImageEnhance.Contrast(image)\n",
    "            image = contrast.enhance(2)\n",
    "            ocr_text = pytesseract.image_to_string(image)\n",
    "            df.at[index, 'ocr_text'] = ocr_text\n",
    "        except Exception as e:\n",
    "            log.write(f'Error processing image {row[\"relative_path\"]}: {e}\\n')\n",
    "\n",
    "df.to_csv('../all_csv_images/ocr_PIL_enhance.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei diesem Beispiel wurde versucht mit cv2 anstatt mit PIL die Bilder vorzuverarbeiten, jedoch waren die Ergebnisse sehr ähnlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing OCR: 100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pytesseract\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import cv2\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = (\n",
    "    r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    ")\n",
    "\n",
    "logging.basicConfig(filename='ocr.log', level=logging.DEBUG)\n",
    "\n",
    "df = pd.read_csv('../all_csv_images/test_file.csv')\n",
    "\n",
    "df['ocr_text'] = ''\n",
    "\n",
    "with open(\"ocr_log.txt\", \"w\") as log:\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc='Performing OCR'):\n",
    "        try:\n",
    "            image = cv2.imread(row['relative_path'])\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.medianBlur(gray, 3)\n",
    "            gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            ocr_text = pytesseract.image_to_string(gray)\n",
    "            df.at[index, 'ocr_text'] = ocr_text\n",
    "        except Exception as e:\n",
    "            log.write(f'Error processing image {row[\"relative_path\"]}: {e}\\n')\n",
    "\n",
    "df.to_csv('../all_csv_images/ocr_cv2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle des Codes: https://cloud.google.com/vision/docs/ocr?hl=de"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Google Vision API können die Bilder ohne Vorverarbeitung an die API geschickt werden. Der erkannte Text wird in einem JSON-Format zurückgegeben. Aus diesen JSON Dateien wird der Text in einer CSV Datei gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing OCR: 100%|██████████| 28052/28052 [6:08:50<00:00,  1.27it/s]   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_csv('../all_csv_images/all_data_all_images_no_duplicates.csv')\n",
    "\n",
    "\n",
    "df['ocr_text'] = ''\n",
    "# Die Credentials wurden hier gelöscht, da sie nicht öffentlich sein sollten\n",
    "credentials = service_account.Credentials.from_service_account_file('')\n",
    "\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "with open(\"ocr_log.txt\", \"w\") as log:\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc='Performing OCR'):\n",
    "        try:\n",
    "            with io.open(row['relative_path'], 'rb') as image_file:\n",
    "                content = image_file.read()\n",
    "            image = vision.Image(content=content)\n",
    "            response = client.text_detection(image=image)\n",
    "            ocr_text = response.text_annotations\n",
    "            df.at[index, 'ocr_text'] = ocr_text[0].description\n",
    "        except Exception as e:\n",
    "            log.write(f'Error processing image {row[\"relative_path\"]}: {e}\\n')\n",
    "\n",
    "\n",
    "    df.to_csv('../all_csv_images/ocr_google_vision.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Memes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c69359b6ae85b7b355cd7fe651d90166f8bb81f2b92a82eabc2dd531a72e3ba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
